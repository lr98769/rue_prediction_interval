{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "493206f9",
   "metadata": {},
   "source": [
    "# Load Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96396dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "\n",
    "data_label = \"mimic\"\n",
    "seed = 2023\n",
    "\n",
    "# File paths\n",
    "fp_notebooks_folder = \"../\"\n",
    "fp_code_folder = os.path.join(fp_notebooks_folder, \"../\")\n",
    "fp_processed_folder = os.path.join(fp_code_folder, \"processed_data\", \"mimic\")\n",
    "fp_downsampled_folder = os.path.join(fp_processed_folder, \"downsampled\")\n",
    "fp_downsampled_dropna_file = os.path.join(fp_downsampled_folder, \"dropna.csv\")\n",
    "fp_downsampled_scaler_file = os.path.join(fp_processed_folder, \"scaler.pkl\")\n",
    "\n",
    "fp_project_checkpoints = os.path.join(fp_code_folder, \"checkpoints\", data_label)\n",
    "fp_tuning = os.path.join(fp_project_checkpoints, \"tuning\")\n",
    "fp_project_models = os.path.join(fp_project_checkpoints, \"models\")\n",
    "fp_project_predictions = os.path.join(fp_project_checkpoints, \"predictions\")\n",
    "fp_project_pi_predictions = os.path.join(fp_project_checkpoints, \"pi_predictions\")\n",
    "fp_project_model_evaluations = os.path.join(fp_project_checkpoints, \"model_evaluation\")\n",
    "fp_project_consolidated_results = os.path.join(fp_project_checkpoints, \"consolidated_results\")\n",
    "fp_time_log = os.path.join(fp_project_consolidated_results, \"runtime.log\")\n",
    "\n",
    "def create_folder(fp):\n",
    "    if not os.path.exists(fp):\n",
    "        os.makedirs(fp)\n",
    "        return True\n",
    "    else:\n",
    "        False\n",
    "\n",
    "def create_all_seed_folders(cur_seed):\n",
    "    fp_checkpoint_folders = [fp_project_models, fp_tuning, fp_project_predictions, fp_project_model_evaluations, fp_project_pi_predictions]\n",
    "    for fp_folder in fp_checkpoint_folders:\n",
    "        fp = os.path.join(fp_folder, str(cur_seed))\n",
    "        create_folder(fp)\n",
    "    print(f\"All folders created for seed = {cur_seed}!\")\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Create all folders\n",
    "create_all_seed_folders(seed)\n",
    "create_folder(fp_project_consolidated_results)\n",
    "\n",
    "# Check GPU is available\n",
    "# print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# function to show df\n",
    "def display_df(df):\n",
    "    display(df.head())\n",
    "    print(\"Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88b18b7",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf1d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(fp_downsampled_dropna_file, index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021d856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"train\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0054cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"valid\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a7c86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"test\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf2ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = df.columns[:60].to_list()\n",
    "print(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ebb623",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols_1 = [col for col in df.columns if \"PredMin1\" in col]\n",
    "pred_cols_2 = [col for col in df.columns if \"PredMin2\" in col]\n",
    "pred_cols_3 = [col for col in df.columns if \"PredMin3\" in col]\n",
    "print(pred_cols_1)\n",
    "print(pred_cols_2)\n",
    "print(pred_cols_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9d8a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make train, validation and test sets\n",
    "def train_valid_test_split(df, pred_cols):\n",
    "    df_train, df_valid, df_test = df[df[\"train\"]], df[df[\"valid\"]], df[df[\"test\"]]\n",
    "    num_pred_cols = len(pred_cols)\n",
    "    \n",
    "    # Plot distribution of pred_col for each set\n",
    "    fig, axes = plt.subplots(num_pred_cols, 3, figsize=(10, 2*num_pred_cols))\n",
    "    for i, col in enumerate(pred_cols):\n",
    "        axes[i, 0].hist(df_train[col])\n",
    "        axes[i, 0].set_xlabel(\"Train\")\n",
    "        axes[i, 0].set_ylabel(col.split(\"_\")[0])\n",
    "        axes[i, 1].hist(df_valid[col])\n",
    "        axes[i, 1].set_xlabel(\"Valid\")\n",
    "        axes[i, 2].hist(df_test[col])\n",
    "        axes[i, 2].set_xlabel(\"Test\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    return df_train, df_valid, df_test\n",
    "\n",
    "df_train_1, df_valid_1, df_test_1 = train_valid_test_split(df, pred_cols=pred_cols_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a052881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_2, df_valid_2, df_test_2 = train_valid_test_split(df, pred_cols=pred_cols_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08e107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_3, df_valid_3, df_test_3 = train_valid_test_split(df, pred_cols=pred_cols_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f7ae42",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe9287",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dict = {\n",
    "    \"t+1\": {\"train_df\": df_train_1, \"valid_df\": df_valid_1, \"test_df\": df_test_1, \"outputs\": pred_cols_1},\n",
    "    \"t+2\": {\"train_df\": df_train_2, \"valid_df\": df_valid_2, \"test_df\": df_test_2, \"outputs\": pred_cols_2},\n",
    "    \"t+3\": {\"train_df\": df_train_3, \"valid_df\": df_valid_3, \"test_df\": df_test_3, \"outputs\": pred_cols_3},\n",
    "}\n",
    "joblib.dump(split_dict, os.path.join(fp_processed_folder, \"mimic_split_dict.joblib\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
